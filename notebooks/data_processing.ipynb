{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T02:56:53.630061Z",
     "start_time": "2024-03-06T02:56:53.021096Z"
    }
   },
   "id": "9c21df4e99539a4d",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "polars.config.Config"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "import dotenv\n",
    "import opendal\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import polars.selectors as s\n",
    "from pyarrow import fs\n",
    "from pyarrow.dataset import dataset\n",
    "from deltalake import DeltaTable\n",
    "pl.Config().set_tbl_cols(-1)\n",
    "\n",
    "# from src.helpers.utils import create_date_directories\n",
    "# from src.scripts.io import sink_to_s3\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:38:59.254619Z",
     "start_time": "2024-03-06T15:38:59.238090Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec46febab49d5b76",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:04:49.121541Z",
     "start_time": "2024-03-02T14:04:49.098086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "base_path = \"../data/log_content/\"\n",
    "s3_path = \"/data/log_content\"\n",
    "start_date = \"20220401\"\n",
    "end_date = \"20220430\"\n",
    "directory_paths = create_date_directories(base_path, start_date, end_date)\n",
    "s3_paths = create_date_directories(s3_path, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1202f84ee6bf635",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ingest_log():\n",
    "    dotenv.load_dotenv()\n",
    "    access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    region = os.getenv(\"AWS_REGION\")\n",
    "    op = opendal.Operator(\n",
    "        \"s3\",\n",
    "        root='/log_content/',\n",
    "        bucket='data',\n",
    "        region=region,\n",
    "        endpoint='http://127.0.0.1:9000',\n",
    "        access_key_id=access_key_id,\n",
    "        secret_access_key=secret_access_key,\n",
    "    )\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0048e7c783d98b0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:11:22.923582Z",
     "start_time": "2024-03-01T10:11:22.896682Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def ingest_by_pyarrow(paths: str):\n",
    "    dotenv.load_dotenv()\n",
    "    cloudfs = fs.S3FileSystem(\n",
    "        access_key=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        secret_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        region=os.getenv(\"AWS_REGION\"),\n",
    "        endpoint_override='http://127.0.0.1:9000',\n",
    "    )\n",
    "    schema = pa.schema([\n",
    "        pa.field('_index', pa.string()),\n",
    "        pa.field('_type', pa.string()),\n",
    "        pa.field('_id', pa.string()),\n",
    "        pa.field('_score', pa.int64()),\n",
    "        pa.field('_source',\n",
    "                 pa.struct(\n",
    "                     [\n",
    "                         pa.field('Contract', pa.string()),\n",
    "                         pa.field('Mac', pa.string()),\n",
    "                         pa.field('TotalDuration', pa.int64()),\n",
    "                         pa.field('AppName', pa.string()),\n",
    "                     ]\n",
    "                 )\n",
    "                 )\n",
    "    ]\n",
    "    )\n",
    "    s3_files = [\n",
    "        entry.path\n",
    "        for entry in cloudfs.get_file_info(fs.FileSelector(paths, recursive=True))\n",
    "    ]\n",
    "\n",
    "    df = []\n",
    "\n",
    "    for path in s3_files:\n",
    "        ds = dataset(\n",
    "            source=path,\n",
    "            schema=schema,\n",
    "            filesystem=cloudfs,\n",
    "            format='json',\n",
    "        )\n",
    "        df.append(\n",
    "            pl.scan_pyarrow_dataset(ds)\n",
    "            .with_columns(pl.Series(\"Date\", [path]).str.extract(r\"\\d{8}\", 0))\n",
    "            .select(\n",
    "                pl.col(\"Date\").str.to_date(\"%Y %m %d\"),\n",
    "                pl.col(\"_index\").alias(\"Index\"),\n",
    "                pl.col(\"_type\").alias(\"Type\"),\n",
    "                pl.col(\"_id\").alias(\"Id\"),\n",
    "                pl.col(\"_score\").alias(\"Score\"),\n",
    "                pl.col(\"_source\"),\n",
    "            )\n",
    "            .unnest(\"_source\")\n",
    "        )\n",
    "\n",
    "    return pl.concat(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9150ae594f656583",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:23:11.352821Z",
     "start_time": "2024-03-01T10:23:10.961643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('Date', Date), ('TotalDuration', Int64)])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = (ingest_by_pyarrow(\"data/log_content/\")\n",
    "           .filter(\n",
    "    pl.col(\"Date\").is_between(pl.datetime(2022, 4, 1), pl.datetime(2022, 4, 3))\n",
    ")\n",
    "           .select(pl.col(\"Date\"), pl.col(\"TotalDuration\")))\n",
    "sources.schema"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sink_to_s3(\n",
    "    sources,\n",
    "    path=\"data/log_content.parquet\",\n",
    "    partition_cols=[\"Date\"],\n",
    "    existing_data_behavior='delete_matching',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:25:15.562746Z",
     "start_time": "2024-03-01T10:24:50.464997Z"
    }
   },
   "id": "5facc85d5b2395e7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6cc1eb821ade5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ingest_by_pyarrow_batches(paths: List[str] = None):\n",
    "    dotenv.load_dotenv()\n",
    "    cloudfs = fs.S3FileSystem(\n",
    "        access_key=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        secret_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        region=os.getenv(\"AWS_REGION\"),\n",
    "        endpoint_override='http://127.0.0.1:9000',\n",
    "    )\n",
    "\n",
    "    schema = pa.schema([\n",
    "        pa.field('_index', pa.string()),\n",
    "        pa.field('_type', pa.string()),\n",
    "        pa.field('_id', pa.string()),\n",
    "        pa.field('_score', pa.int64()),\n",
    "        pa.field('_source',\n",
    "                 pa.struct(\n",
    "                     [\n",
    "                         pa.field('Contract', pa.string()),\n",
    "                         pa.field('Mac', pa.string()),\n",
    "                         pa.field('TotalDuration', pa.int64()),\n",
    "                         pa.field('AppName', pa.string()),\n",
    "                     ]\n",
    "                 )\n",
    "                 )\n",
    "    ]\n",
    "    )\n",
    "    df = []\n",
    "\n",
    "    for path in paths:\n",
    "        ds = dataset(\n",
    "            source=path,\n",
    "            schema=schema,\n",
    "            filesystem=cloudfs,\n",
    "            format='json',\n",
    "        )\n",
    "        for batch in ds.to_batches():\n",
    "            df.append(\n",
    "                pl.from_arrow(batch)\n",
    "                .lazy()\n",
    "                .with_columns(pl.Series(\"Date\", [path]).str.extract(r\"\\d{8}\", 0))\n",
    "            )\n",
    "\n",
    "    return pl.concat(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ingest_by_pyarrow_batches(s3_paths)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77a9086c178da6a3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0c9fff251a6518d",
   "metadata": {},
   "source": [
    "# Ingest the logging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c31c5a2d53f8d2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:04:59.199998Z",
     "start_time": "2024-03-02T14:04:59.167879Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_log_json(paths: str | list[str]) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Function to ingest the logging json data, get the filename and add a \"Date\" column\n",
    "    Args:\n",
    "        paths (str | list[str]): a list of path to data, this path must be in glob pattern\n",
    "\n",
    "    Returns:\n",
    "        pl.LazyFame\n",
    "    \"\"\"\n",
    "    if isinstance(paths, str):\n",
    "        paths = [paths]\n",
    "    # Define schema of logging data\n",
    "    schema = {\n",
    "        \"_index\" : pl.String,\n",
    "        \"_type\"  : pl.String,\n",
    "        \"_id\"    : pl.String,\n",
    "        \"_score\" : pl.Int64,\n",
    "        \"_source\": pl.Struct(\n",
    "            [\n",
    "                pl.Field(\"Contract\", pl.String),\n",
    "                pl.Field(\"Mac\", pl.String),\n",
    "                pl.Field(\"TotalDuration\", pl.Int64),\n",
    "                pl.Field(\"AppName\", pl.String),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    def _scan_log(path, schema):\n",
    "        return (\n",
    "            pl.scan_ndjson(path, schema=schema, low_memory=True)\n",
    "            .with_columns(pl.Series(\"Date\", [path]).str.extract(r\"\\d{8}\", 0))\n",
    "            .select(\n",
    "                pl.col(\"Date\").str.to_date(\"%Y %m %d\"),\n",
    "                pl.col(\"_index\").alias(\"Index\"),\n",
    "                pl.col(\"_type\").alias(\"Type\"),\n",
    "                pl.col(\"_id\").alias(\"Id\"),\n",
    "                pl.col(\"_score\").alias(\"Score\"),\n",
    "                pl.col(\"_source\"),\n",
    "            )\n",
    "            .unnest(\"_source\")\n",
    "        )\n",
    "\n",
    "    dfs = []\n",
    "    # Function to scan and preprocess a single log data\n",
    "    try:\n",
    "        dfs = [_scan_log(path, schema) for path in paths]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read data from {paths}\", {e})\n",
    "\n",
    "    # Concatenate the processed lazyframes\n",
    "    return pl.concat(dfs, how=\"vertical\").lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc50cd786301652",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:05:00.781067Z",
     "start_time": "2024-03-02T14:05:00.700334Z"
    }
   },
   "outputs": [],
   "source": [
    "sources = get_log_json(directory_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5e11b421f6749",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.concat(\n",
    "    pl.collect_all(\n",
    "        [\n",
    "            dfi.lazy()\n",
    "            for dfi in sources.collect().partition_by(by=\"Date\")\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bdc1ff02875c0",
   "metadata": {},
   "source": [
    "# Get the RFM table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c8eb73de804080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T14:05:05.135222Z",
     "start_time": "2024-03-02T14:05:05.106510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Date',\n 'Index',\n 'Type',\n 'Id',\n 'Score',\n 'Contract',\n 'Mac',\n 'TotalDuration',\n 'AppName']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "369e49a47d9ae5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T14:12:44.801317Z",
     "start_time": "2024-03-02T14:12:44.770839Z"
    }
   },
   "outputs": [],
   "source": [
    "reported_date = \"20220501\"\n",
    "\n",
    "\n",
    "def get_rfm_table(sources: pl.LazyFrame, reported_date: str = \"20220501\", total_date: int = 30) -> pl.LazyFrame:\n",
    "    b: pl.LazyFrame = (\n",
    "        sources.group_by(\"Contract\")\n",
    "        .agg(\n",
    "            pl.col(\"Date\").max().alias(\"LatestDate\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    temp = (\n",
    "        sources.with_columns(\n",
    "            pl.lit(reported_date).str.to_date(\"%Y %m %d\").alias(\"ReportedDate\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rfm = (\n",
    "        temp\n",
    "        .filter(pl.col(\"Contract\").str.len_chars() > 1)\n",
    "        .join(b, on=\"Contract\", how='left')\n",
    "        .group_by(\"Contract\")\n",
    "        .agg(\n",
    "            (pl.col(\"ReportedDate\") - pl.col(\"LatestDate\")).min().alias(\"Recency\"),\n",
    "            (pl.col(\"Date\").n_unique() / pl.lit(total_date) * 100.0).round(2).alias(\"Frequency\"),\n",
    "            pl.sum(\"TotalDuration\").alias(\"Monetary\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"Recency\").qcut(3, labels=[\"1\", \"2\", \"3\"], allow_duplicates=True).alias(\"R\"),\n",
    "            pl.col(\"Frequency\").qcut(3, labels=[\"1\", \"2\", \"3\"], allow_duplicates=True).alias(\"F\"),\n",
    "            pl.col(\"Monetary\").qcut(3, labels=[\"1\", \"2\", \"3\"], allow_duplicates=True).alias(\"M\"),\n",
    "        )\n",
    "        .select(\n",
    "            pl.col(\"Contract\"),\n",
    "            pl.concat_str([pl.col(\"R\"), pl.col(\"F\"), pl.col(\"M\")]).alias(\"RFM\"),\n",
    "            pl.lit(reported_date).str.strptime(pl.Date, format=\"%Y%m%d\").alias(\"ReportedDate\")\n",
    "        )\n",
    "        .sort(\"RFM\")\n",
    "    )\n",
    "\n",
    "    return rfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ca74ebbb5ae50c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:12:45.876038Z",
     "start_time": "2024-03-02T14:12:45.827542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (2_966, 2)\n┌─────┬──────────────┐\n│ RFM ┆ ReportedDate │\n│ --- ┆ ---          │\n│ str ┆ date         │\n╞═════╪══════════════╡\n│ 111 ┆ 2022-05-01   │\n│ 111 ┆ 2022-05-01   │\n│ 111 ┆ 2022-05-01   │\n│ 111 ┆ 2022-05-01   │\n│ 111 ┆ 2022-05-01   │\n│ …   ┆ …            │\n│ 313 ┆ 2022-05-01   │\n│ 313 ┆ 2022-05-01   │\n│ 313 ┆ 2022-05-01   │\n│ 313 ┆ 2022-05-01   │\n│ 332 ┆ 2022-05-01   │\n└─────┴──────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2_966, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>RFM</th><th>ReportedDate</th></tr><tr><td>str</td><td>date</td></tr></thead><tbody><tr><td>&quot;111&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;111&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;111&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;111&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;111&quot;</td><td>2022-05-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;313&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;313&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;313&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;313&quot;</td><td>2022-05-01</td></tr><tr><td>&quot;332&quot;</td><td>2022-05-01</td></tr></tbody></table></div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rfm_table(sources).fetch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e71e446594927",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_names = [\n",
    "    \"CHANNEL\",\n",
    "    \"KPLUS\",\n",
    "    \"VOD\",\n",
    "    \"FIMS\",\n",
    "    \"BHD\",\n",
    "    \"SPORT\",\n",
    "    \"CHILD\",\n",
    "    \"RELAX\",\n",
    "]\n",
    "\n",
    "column_names = [\n",
    "    \"TVDuration\",\n",
    "    \"TVDuration\",\n",
    "    \"MovieDuration\",\n",
    "    \"MovieDuration\",\n",
    "    \"MovieDuration\",\n",
    "    \"SportDuration\",\n",
    "    \"ChildDuration\",\n",
    "    \"RelaxDuration\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_pivot_data(sources: pl.LazyFrame, app_names: List[str], column_names: List[str]) -> pl.LazyFrame:\n",
    "    if not isinstance(sources, pl.LazyFrame):\n",
    "        sources = sources.lazy()\n",
    "\n",
    "    if len(app_names) != len(column_names):\n",
    "        raise ValueError(\"The lengths of app_names and column_names must be the same\")\n",
    "\n",
    "    mapping = dict(zip(app_names, column_names))\n",
    "    pivot_df: pl.LazyFrame = (\n",
    "        sources.select(\n",
    "            pl.col(\"Contract\"),\n",
    "            pl.col(\"TotalDuration\"),\n",
    "            pl.col(\"AppName\").replace(mapping, default=\"Unknown\").alias(\"Type\")\n",
    "        )\n",
    "        .filter(\n",
    "            (pl.col(\"Contract\").str.len_chars() > 1)\n",
    "            & (pl.col(\"Type\") != \"Unknown\")\n",
    "            & (pl.col(\"TotalDuration\") > 0)\n",
    "        )\n",
    "        .group_by([\"Contract\"])\n",
    "        .agg(\n",
    "            [\n",
    "                pl.when(pl.col(\"Type\") == y).then(pl.col(\"TotalDuration\")).sum().alias(y)\n",
    "                for y in set(column_names)\n",
    "            ]\n",
    "        )\n",
    "        .sort([\"Contract\", \"TVDuration\"])\n",
    "    )\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86971fedc736ee98",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_most_watch(sources: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    if not isinstance(sources, pl.LazyFrame):\n",
    "        sources = sources.lazy()\n",
    "    columns = sources.columns[1:]\n",
    "    watch_type = [item[:-8] for item in columns]\n",
    "\n",
    "    return (\n",
    "        sources\n",
    "        .with_columns(\n",
    "            pl.concat_list([\n",
    "                pl.struct(pl.col(c).alias(\"l\"), pl.lit(v).alias(\"k\")) for c, v in zip(columns, watch_type)\n",
    "                for c, v in zip(columns, watch_type)\n",
    "            ]\n",
    "            ).alias('temp')\n",
    "        )\n",
    "        .select(\n",
    "            pl.col('Contract'),\n",
    "            pl.col('temp').list.sort(descending=True).list.first().struct.field('k').alias('MostWatch')\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6ad7a5383693f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot_df = get_pivot_data(sources, app_names, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71486f3a3ebf887b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot_df.fetch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea61747cb17902",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_most_watch(pivot_df).fetch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ff054ac24d500",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pivot_df.with_columns(\n",
    "    pl.concat_list([pl.struct(pl.col(c).alias(\"l\"), pl.lit(v).alias(\"k\")) for c, v in zip(columns, watch_type)]).alias(\n",
    "        'temp'\n",
    "    )\n",
    ").select(\n",
    "    pl.col('Contract'),\n",
    "    pl.col('temp').list.sort(descending=True).list.first().struct.field('k')\n",
    ")\n",
    " .fetch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad38ca218723277",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2871e0fbaa01e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_list = ['MovieDuration', 'TVDuration', 'RelaxDuration', 'ChildDuration', 'SportDuration']\n",
    "filtered_list = [item for item in original_list if 'Duration' not in item]\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SCP Type 2 Supported Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "156d125e478666c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.scripts.support import type2_scd_upsert_pl\n",
    "import polars as pl"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:48:11.551640Z",
     "start_time": "2024-03-07T13:48:10.935392Z"
    }
   },
   "id": "5a4fd8d3b005300c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# test data \n",
    "sources_df = pl.DataFrame([\n",
    "    {\"pkey\"    : 1, \"attr1\": \"A\", \"attr2\": \"A\", \"is_current\": True, \"effective_time\": \"2019-01-01 00:00:00\",\n",
    "     \"end_time\": None},\n",
    "    {\"pkey\"    : 2, \"attr1\": \"B\", \"attr2\": \"B\", \"is_current\": True, \"effective_time\": \"2019-01-01 00:00:00\",\n",
    "     \"end_time\": None},\n",
    "    {\"pkey\"    : 4, \"attr1\": \"D\", \"attr2\": \"D\", \"is_current\": True, \"effective_time\": \"2019-01-01 00:00:00\",\n",
    "     \"end_time\": None},\n",
    "]\n",
    ")\n",
    "updates_df = pl.DataFrame(\n",
    "    [\n",
    "        {\"pkey\": 2, \"attr1\": \"Z\", \"attr2\": \"null\", \"effective_time\": \"2020-01-01 00:00:00\"},\n",
    "        {\"pkey\": 3, \"attr1\": \"C\", \"attr2\": \"C\", \"effective_time\": \"2020-09-15 00:00:00\"},\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:53:58.208654Z",
     "start_time": "2024-03-07T13:53:58.202955Z"
    }
   },
   "id": "fa5d229391ed8a59",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌──────┬───────┬───────┬────────────┬─────────────────────┬──────────┐\n",
      "│ pkey ┆ attr1 ┆ attr2 ┆ is_current ┆ effective_time      ┆ end_time │\n",
      "│ ---  ┆ ---   ┆ ---   ┆ ---        ┆ ---                 ┆ ---      │\n",
      "│ i64  ┆ str   ┆ str   ┆ bool       ┆ str                 ┆ null     │\n",
      "╞══════╪═══════╪═══════╪════════════╪═════════════════════╪══════════╡\n",
      "│ 1    ┆ A     ┆ A     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null     │\n",
      "│ 2    ┆ B     ┆ B     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null     │\n",
      "│ 4    ┆ D     ┆ D     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null     │\n",
      "└──────┴───────┴───────┴────────────┴─────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(sources_df)\n",
    "sources_df.cast({\"end_time\": pl.Datetime}).write_delta(target='./delta_lake1/product', mode=\"overwrite\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:48:16.152701Z",
     "start_time": "2024-03-07T13:48:15.988404Z"
    }
   },
   "id": "7369d9485770ec1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "updates_df = updates_df.with_columns(pl.col('effective_time').str.to_datetime())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:54:00.221401Z",
     "start_time": "2024-03-07T13:54:00.218300Z"
    }
   },
   "id": "db02107ea682ae9f",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 1)\n",
      "┌─────────────────────┐\n",
      "│ effective_time      │\n",
      "│ ---                 │\n",
      "│ datetime[μs]        │\n",
      "╞═════════════════════╡\n",
      "│ 2020-01-01 00:00:00 │\n",
      "│ 2020-09-15 00:00:00 │\n",
      "└─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(updates_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:50:54.801449Z",
     "start_time": "2024-03-07T13:50:54.797222Z"
    }
   },
   "id": "1f53c11ee8967a72",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sources1_df = pl.scan_delta(\"./delta_lake1/product\").with_columns(\n",
    "    pl.col('effective_time').str.to_datetime(),\n",
    "    pl.col('end_time').str.to_datetime(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:52:49.653057Z",
     "start_time": "2024-03-07T13:52:49.640643Z"
    }
   },
   "id": "624daf4b89c46bb0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌──────┬───────┬───────┬────────────┬─────────────────────┬──────────────┐\n",
      "│ pkey ┆ attr1 ┆ attr2 ┆ is_current ┆ effective_time      ┆ end_time     │\n",
      "│ ---  ┆ ---   ┆ ---   ┆ ---        ┆ ---                 ┆ ---          │\n",
      "│ i64  ┆ str   ┆ str   ┆ bool       ┆ datetime[μs]        ┆ datetime[μs] │\n",
      "╞══════╪═══════╪═══════╪════════════╪═════════════════════╪══════════════╡\n",
      "│ 1    ┆ A     ┆ A     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null         │\n",
      "│ 2    ┆ B     ┆ B     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null         │\n",
      "│ 4    ┆ D     ┆ D     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null         │\n",
      "└──────┴───────┴───────┴────────────┴─────────────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(sources1_df.collect())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:52:51.191116Z",
     "start_time": "2024-03-07T13:52:51.185141Z"
    }
   },
   "id": "4c006c2739503e2a",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'num_source_rows': 3,\n 'num_target_rows_inserted': 1,\n 'num_target_rows_updated': 2,\n 'num_target_rows_deleted': 0,\n 'num_target_rows_copied': 2,\n 'num_output_rows': 5,\n 'num_target_files_added': 2,\n 'num_target_files_removed': 1,\n 'execution_time_ms': 203,\n 'scan_time_ms': 0,\n 'rewrite_time_ms': 27}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_scd_upsert_pl(\n",
    "    sources1_df,\n",
    "    updates_df.lazy(),\n",
    "    'pkey',\n",
    "    \"./delta_lake1/product\",\n",
    "    ['attr1', 'attr2'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T13:54:04.514303Z",
     "start_time": "2024-03-07T13:54:04.248644Z"
    }
   },
   "id": "bdb18612e78bfaa0",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      " WITH_COLUMNS:\n",
      " [true.alias(\"is_current\"), null.alias(\"end_time\").strict_cast(Datetime(Microseconds, None))]\n",
      "  ANTI JOIN:\n",
      "  LEFT PLAN ON: [col(\"pkey\")]\n",
      "    DF [\"pkey\", \"attr1\", \"attr2\", \"effective_time\"]; PROJECT */4 COLUMNS; SELECTION: \"None\"\n",
      "  RIGHT PLAN ON: [col(\"pkey\")]\n",
      "    DF [\"pkey\", \"attr1\", \"attr2\", \"is_current\"]; PROJECT */6 COLUMNS; SELECTION: \"None\"\n",
      "  END ANTI JOIN\n"
     ]
    }
   ],
   "source": [
    "# new record\n",
    "new_records = updates_df.lazy().join(sources_df.lazy(), on=\"pkey\", how=\"anti\").with_columns(pl.lit(True).alias(\"is_current\"), pl.lit(None).alias(\"end_time\").cast(pl.Datetime))\n",
    "print(new_records)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:36.412004Z",
     "start_time": "2024-03-06T16:08:36.406827Z"
    }
   },
   "id": "4e502dfd74e8c6bc",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "conversion from `str` to `datetime[μs]` failed in column 'effective_time' for 1 out of 1 values: [\"2020-09-15 00:00:00\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mComputeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mnew_records\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meffective_time\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDatetime\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/polarspipeline-hi-VSseM-py3.11/lib/python3.11/site-packages/polars/dataframe/frame.py:6870\u001B[0m, in \u001B[0;36mDataFrame.cast\u001B[0;34m(self, dtypes, strict)\u001B[0m\n\u001B[1;32m   6788\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcast\u001B[39m(\n\u001B[1;32m   6789\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   6790\u001B[0m     dtypes: (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   6795\u001B[0m     strict: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   6796\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m   6797\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6798\u001B[0m \u001B[38;5;124;03m    Cast DataFrame column(s) to the specified dtype(s).\u001B[39;00m\n\u001B[1;32m   6799\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   6868\u001B[0m \u001B[38;5;124;03m     'ham': ['2020-01-02', '2021-03-04', '2022-05-06']}\u001B[39;00m\n\u001B[1;32m   6869\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 6870\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_eager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/polarspipeline-hi-VSseM-py3.11/lib/python3.11/site-packages/polars/lazyframe/frame.py:1939\u001B[0m, in \u001B[0;36mLazyFrame.collect\u001B[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001B[0m\n\u001B[1;32m   1936\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m background:\n\u001B[1;32m   1937\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m InProcessQuery(ldf\u001B[38;5;241m.\u001B[39mcollect_concurrently())\n\u001B[0;32m-> 1939\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_df(ldf\u001B[38;5;241m.\u001B[39mcollect())\n",
      "\u001B[0;31mComputeError\u001B[0m: conversion from `str` to `datetime[μs]` failed in column 'effective_time' for 1 out of 1 values: [\"2020-09-15 00:00:00\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string"
     ]
    }
   ],
   "source": [
    "print(new_records.collect().cast({\"effective_time\": pl.Datetime}))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:25.083504Z",
     "start_time": "2024-03-06T16:10:25.035221Z"
    }
   },
   "id": "f23d4e9d281014e5",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (0, 6)\n┌──────┬───────┬───────┬────────────┬────────────────┬──────────┐\n│ pkey ┆ attr1 ┆ attr2 ┆ is_current ┆ effective_time ┆ end_time │\n│ ---  ┆ ---   ┆ ---   ┆ ---        ┆ ---            ┆ ---      │\n│ i64  ┆ str   ┆ str   ┆ bool       ┆ str            ┆ null     │\n╞══════╪═══════╪═══════╪════════════╪════════════════╪══════════╡\n└──────┴───────┴───────┴────────────┴────────────────┴──────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (0, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pkey</th><th>attr1</th><th>attr2</th><th>is_current</th><th>effective_time</th><th>end_time</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>bool</td><td>str</td><td>null</td></tr></thead><tbody></tbody></table></div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleted records\n",
    "(\n",
    "    sources_df\n",
    "    .filter(\n",
    "        pl.col(\"is_current\") == \"True\"\n",
    "    )\n",
    "    .join(\n",
    "        other=updates_df,\n",
    "        on=\"pkey\",\n",
    "        how=\"anti\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T16:44:07.080410Z",
     "start_time": "2024-03-05T16:44:07.053053Z"
    }
   },
   "id": "5d6a4f2e92bf2fa",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<Expr ['[(col(\"attr1\")) != (col(\"attr1…'] at 0x12423C190>,\n <Expr ['[(col(\"attr2\")) != (col(\"attr2…'] at 0x12423FF40>]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(pl.col(f\"{attr}\") != pl.col(f\"{attr}_right\")) for attr in ['attr1', 'attr2']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T03:38:09.941536Z",
     "start_time": "2024-03-06T03:38:09.917796Z"
    }
   },
   "id": "d55d74b833e1ba28",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 6)\n",
      "┌──────┬───────┬───────┬─────────────────────┬────────────┬──────────┐\n",
      "│ pkey ┆ attr1 ┆ attr2 ┆ effective_time      ┆ is_current ┆ end_time │\n",
      "│ ---  ┆ ---   ┆ ---   ┆ ---                 ┆ ---        ┆ ---      │\n",
      "│ i64  ┆ str   ┆ str   ┆ str                 ┆ bool       ┆ str      │\n",
      "╞══════╪═══════╪═══════╪═════════════════════╪════════════╪══════════╡\n",
      "│ 2    ┆ Z     ┆ null  ┆ 2020-01-01 00:00:00 ┆ true       ┆ null     │\n",
      "└──────┴───────┴───────┴─────────────────────┴────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "opened_records = (sources_df\n",
    ".join(updates_df, on=\"pkey\", how=\"inner\")\n",
    ".filter(\n",
    "    pl.any_horizontal(\n",
    "        (pl.col(\"is_current\") == \"True\"),\n",
    "        *[(pl.col(f\"{attr}\") != pl.col(f\"{attr}_right\")) for attr in ['attr1', 'attr2']]\n",
    "    )\n",
    ")\n",
    ".select(\n",
    "    pl.col(\"pkey\"),\n",
    "    *[(pl.col(f\"{attr}_right\").alias(f\"{attr}\")) for attr in ['attr1', 'attr2']],\n",
    "    pl.col(\"effective_time_right\").alias(\"effective_time\"),\n",
    "    pl.lit(True).alias(\"is_current\"),\n",
    "    pl.lit(None).alias(\"end_time\").cast(pl.String)\n",
    ")\n",
    ")\n",
    "print(opened_records)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:44:14.996435Z",
     "start_time": "2024-03-06T05:44:14.979190Z"
    }
   },
   "id": "ba888576be0f8537",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 6)\n",
      "┌──────┬───────┬───────┬────────────┬─────────────────────┬─────────────────────┐\n",
      "│ pkey ┆ attr1 ┆ attr2 ┆ is_current ┆ effective_time      ┆ end_time            │\n",
      "│ ---  ┆ ---   ┆ ---   ┆ ---        ┆ ---                 ┆ ---                 │\n",
      "│ i64  ┆ str   ┆ str   ┆ bool       ┆ str                 ┆ str                 │\n",
      "╞══════╪═══════╪═══════╪════════════╪═════════════════════╪═════════════════════╡\n",
      "│ 2    ┆ B     ┆ B     ┆ false      ┆ 2019-01-01 00:00:00 ┆ 2020-01-01 00:00:00 │\n",
      "└──────┴───────┴───────┴────────────┴─────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "closed_records = (sources_df\n",
    ".join(updates_df, on=\"pkey\", how=\"inner\")\n",
    ".filter(\n",
    "    pl.any_horizontal(\n",
    "        (pl.col(\"is_current\") == \"True\"),\n",
    "        *[(pl.col(f\"{attr}\") != pl.col(f\"{attr}_right\")) for attr in ['attr1', 'attr2']]\n",
    "    )\n",
    ")\n",
    ".select(\n",
    "    pl.col(\"pkey\"),\n",
    "    *[(pl.col(f\"{attr}\").alias(f\"{attr}\")) for attr in ['attr1', 'attr2']],\n",
    "    pl.lit(False).alias(\"is_current\"),\n",
    "    pl.col(\"effective_time\"),\n",
    "    pl.col(\"effective_time_right\").alias(\"end_time\"),\n",
    ")\n",
    ")\n",
    "print(closed_records)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:39:13.358132Z",
     "start_time": "2024-03-06T05:39:13.330594Z"
    }
   },
   "id": "b5a58012abeb6891",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# insert records\n",
    "upsert_records = pl.concat([\n",
    "    opened_records,\n",
    "    new_records,\n",
    "    closed_records,\n",
    "],\n",
    "how=\"align\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:47:47.573715Z",
     "start_time": "2024-03-06T05:47:47.552709Z"
    }
   },
   "id": "a2333d64ab4afd35",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "┌──────┬───────┬───────┬────────────┬─────────────────────┬─────────────────────┐\n",
      "│ pkey ┆ attr1 ┆ attr2 ┆ is_current ┆ effective_time      ┆ end_time            │\n",
      "│ ---  ┆ ---   ┆ ---   ┆ ---        ┆ ---                 ┆ ---                 │\n",
      "│ i64  ┆ str   ┆ str   ┆ bool       ┆ str                 ┆ str                 │\n",
      "╞══════╪═══════╪═══════╪════════════╪═════════════════════╪═════════════════════╡\n",
      "│ 1    ┆ A     ┆ A     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null                │\n",
      "│ 2    ┆ B     ┆ B     ┆ false      ┆ 2019-01-01 00:00:00 ┆ 2020-01-01 00:00:00 │\n",
      "│ 2    ┆ Z     ┆ null  ┆ true       ┆ 2020-01-01 00:00:00 ┆ null                │\n",
      "│ 3    ┆ C     ┆ C     ┆ true       ┆ 2020-09-15 00:00:00 ┆ null                │\n",
      "│ 4    ┆ D     ┆ D     ┆ true       ┆ 2019-01-01 00:00:00 ┆ null                │\n",
      "└──────┴───────┴───────┴────────────┴─────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "upsert_records.write_delta(\n",
    "    target='./delta_lake1/product',\n",
    "    mode='merge',\n",
    "    delta_merge_options={\n",
    "        'predicate': 'source.pkey = target.pkey',\n",
    "        'source_alias': 'source',\n",
    "        'target_alias' : 'target',\n",
    "    }\n",
    ").when_matched_update_all().when_not_matched_insert_all().execute()\n",
    "\n",
    "new_df = pl.read_delta(source='./delta_lake1/product').sort('pkey')\n",
    "\n",
    "print(new_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T05:50:39.190518Z",
     "start_time": "2024-03-06T05:50:38.959925Z"
    }
   },
   "id": "a3bde186853170c3",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "\n",
    "def type2_scd_upsert_pl(\n",
    "    sources_df: pl.LazyFrame,\n",
    "    updates_df: pl.LazyFrame,\n",
    "    primary_key: str,\n",
    "    target: str,\n",
    "    attr_cols: List[str],\n",
    "    is_current_col: str = \"is_current\",\n",
    "    effective_time_col: str = \"effective_time\",\n",
    "    end_time_col: str = \"end_time\",\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform a Type 2 Slowly Changing Dimension (SCD) upsert operation using Polars LazyFrame/DataFrame and\n",
    "    write to Delta Lake using pl.write_delta().\n",
    "\n",
    "    Args:\n",
    "        sources_df (pl.LazyFrame): The source or target Polars LazyFrame scanned from DeltaLake using pl.scan_delta().\n",
    "        updates_df (pl.LazyFrame): The Polars LazyFrame representing the updates data.\n",
    "        primary_key (str): The name of the primary key column.\n",
    "        target (str): The name of the target table to write the upserted records.\n",
    "        attr_cols (List[str]): A list of attribute column names.\n",
    "        is_current_col (str, optional): The name of the column indicating if a record is current. Defaults to\n",
    "        \"is_current\".\n",
    "        effective_time_col (str, optional): The name of the column indicating the effective time of a record.\n",
    "        Defaults to \"effective_time\".\n",
    "        end_time_col (str, optional): The name of the column indicating the end time of a record. Defaults to\n",
    "        \"end_time\".\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: A dictionary representing the result of the upsert operation.\n",
    "    \"\"\"\n",
    "    # validate updates delta tables\n",
    "    base_cols = sources_df.columns\n",
    "\n",
    "    required_base_cols = (\n",
    "        [primary_key] + attr_cols + [is_current_col, effective_time_col, end_time_col]\n",
    "    )\n",
    "\n",
    "    if sorted(base_cols) != sorted(required_base_cols):\n",
    "        raise ValueError(\n",
    "            f\"The base columns has to be the same as the required columns: {required_base_cols!r}\"\n",
    "        )\n",
    "    # validate updated polars lazyframe\n",
    "    update_cols = updates_df.columns\n",
    "\n",
    "    required_update_cols = [primary_key] + attr_cols + [effective_time_col]\n",
    "\n",
    "    if sorted(update_cols) != sorted(required_update_cols):\n",
    "        raise ValueError(\n",
    "            f\"The base columns has to be the same as the required columns: {required_update_cols!r}\"\n",
    "        )\n",
    "\n",
    "    new_records = updates_df.join(sources_df, on=primary_key, how=\"anti\").with_columns(\n",
    "        pl.lit(True).alias(is_current_col),\n",
    "        pl.lit(None, pl.Datetime).alias(end_time_col),\n",
    "    )\n",
    "    updates_conds = [\n",
    "        (pl.col(f\"{attr}\") != pl.col(f\"{attr}_right\")) for attr in attr_cols\n",
    "    ]\n",
    "    updates_records = sources_df.join(updates_df, on=primary_key, how=\"inner\").filter(\n",
    "        pl.any_horizontal(\n",
    "            (pl.col(is_current_col) == True),\n",
    "            *updates_conds,\n",
    "        )\n",
    "    )\n",
    "    open_conds = [(pl.col(f\"{attr}_right\").alias(f\"{attr}\")) for attr in attr_cols]\n",
    "    open_records = updates_records.select(\n",
    "        pl.col(primary_key),\n",
    "        *open_conds,\n",
    "        pl.lit(True).alias(is_current_col),\n",
    "        pl.col(f\"{effective_time_col}_right\").alias(f\"{effective_time_col}\"),\n",
    "        pl.lit(None, pl.Datetime).alias(end_time_col),\n",
    "    )\n",
    "\n",
    "    close_conds = [(pl.col(f\"{attr}\").alias(f\"{attr}\")) for attr in attr_cols]\n",
    "    close_records = updates_records.select(\n",
    "        pl.col(primary_key),\n",
    "        *close_conds,\n",
    "        pl.lit(False).alias(is_current_col),\n",
    "        pl.col(effective_time_col),\n",
    "        pl.col(f\"{effective_time_col}_right\").alias(end_time_col),\n",
    "    )\n",
    "\n",
    "    # merging\n",
    "    upsert_records = pl.concat(\n",
    "        [\n",
    "            new_records,\n",
    "            open_records,\n",
    "            close_records,\n",
    "        ],\n",
    "        how=\"align\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        upsert_records.collect(streaming=True)\n",
    "        .write_delta(\n",
    "            target=target,\n",
    "            mode=\"merge\",\n",
    "            delta_merge_options={\n",
    "                \"predicate\": f\"source.{primary_key} = target.{primary_key}\",\n",
    "                \"source_alias\": \"source\",\n",
    "                \"target_alias\": \"target\",\n",
    "            },\n",
    "        )\n",
    "        .when_matched_update_all()\n",
    "        .when_not_matched_insert_all()\n",
    "        .execute()\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:43:06.638093Z",
     "start_time": "2024-03-06T16:43:06.625235Z"
    }
   },
   "id": "96e82bbfeecdd9ee",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sources_df = pl.LazyFrame({\n",
    "    'product_code' : ['0001', '0002', '0003', '0004'],\n",
    "    'color' : ['red', 'green','blue','yellow'],\n",
    "    'size': ['small','medium','large','x-large']\n",
    "}).cast().with_columns(\n",
    "    [\n",
    "        pl.lit(True).alias('is_current'),\n",
    "        pl.lit(datetime(1900,1,1,0,0,0,0)).alias('effective_time'),\n",
    "        pl.lit(None, pl.Datetime).alias('end_time'),\n",
    "    ]\n",
    ")\n",
    "sources_df.collect().write_delta(target='./delta_lake1/product1', mode=\"overwrite\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:34:55.383152Z",
     "start_time": "2024-03-06T16:34:55.322228Z"
    }
   },
   "id": "3fd4417d5fcadf3e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Int64, String, String, Boolean, String, Null]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_df.d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:06:02.549170Z",
     "start_time": "2024-03-06T17:06:02.544590Z"
    }
   },
   "id": "702a85402da85cd8",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "updates_df = pl.LazyFrame({\n",
    "    'product_code' : ['0002', '0003', '0004','0005'],\n",
    "    'color' : ['green','teal','yellow','white'],\n",
    "    'size': ['medium','large','x-large', 'medium']  \n",
    "}).with_columns(\n",
    "    pl.lit(datetime(1999, 1, 20, 0,0,0,0)).alias('effective_time')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:36:05.781738Z",
     "start_time": "2024-03-06T16:36:05.777540Z"
    }
   },
   "id": "97637224d74035e6",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "shape: (4, 4)\n┌──────────────┬────────┬─────────┬─────────────────────┐\n│ product_code ┆ color  ┆ size    ┆ effective_time      │\n│ ---          ┆ ---    ┆ ---     ┆ ---                 │\n│ str          ┆ str    ┆ str     ┆ datetime[μs]        │\n╞══════════════╪════════╪═════════╪═════════════════════╡\n│ 0002         ┆ green  ┆ medium  ┆ 1999-01-20 00:00:00 │\n│ 0003         ┆ teal   ┆ large   ┆ 1999-01-20 00:00:00 │\n│ 0004         ┆ yellow ┆ x-large ┆ 1999-01-20 00:00:00 │\n│ 0005         ┆ white  ┆ medium  ┆ 1999-01-20 00:00:00 │\n└──────────────┴────────┴─────────┴─────────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>product_code</th><th>color</th><th>size</th><th>effective_time</th></tr><tr><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;0002&quot;</td><td>&quot;green&quot;</td><td>&quot;medium&quot;</td><td>1999-01-20 00:00:00</td></tr><tr><td>&quot;0003&quot;</td><td>&quot;teal&quot;</td><td>&quot;large&quot;</td><td>1999-01-20 00:00:00</td></tr><tr><td>&quot;0004&quot;</td><td>&quot;yellow&quot;</td><td>&quot;x-large&quot;</td><td>1999-01-20 00:00:00</td></tr><tr><td>&quot;0005&quot;</td><td>&quot;white&quot;</td><td>&quot;medium&quot;</td><td>1999-01-20 00:00:00</td></tr></tbody></table></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates_df.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:36:13.763467Z",
     "start_time": "2024-03-06T16:36:13.757730Z"
    }
   },
   "id": "dbc99e5fdbc21cd4",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<LazyFrame [6 cols, {\"product_code\": String … \"end_time\": Datetime(time_unit='us', time_zone=None)}] at 0x12621FBB0>",
      "text/html": "<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see the optimized version</p><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n -->\n<!-- Title: polars_query Pages: 1 -->\n<svg width=\"131pt\" height=\"66pt\"\n viewBox=\"0.00 0.00 130.50 65.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 61.5)\">\n<title>polars_query</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-61.5 126.5,-61.5 126.5,4 -4,4\"/>\n<!-- [PYTHON SCAN ;\nπ */6;\nσ &#45;] -->\n<g id=\"node1\" class=\"node\">\n<title>[PYTHON SCAN ;\nπ */6;\nσ &#45;]</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"122.5,-57.5 0,-57.5 0,0 122.5,0 122.5,-57.5\"/>\n<text text-anchor=\"middle\" x=\"61.25\" y=\"-40.2\" font-family=\"Times,serif\" font-size=\"14.00\">[PYTHON SCAN ;</text>\n<text text-anchor=\"middle\" x=\"61.25\" y=\"-23.7\" font-family=\"Times,serif\" font-size=\"14.00\">π */6;</text>\n<text text-anchor=\"middle\" x=\"61.25\" y=\"-7.2\" font-family=\"Times,serif\" font-size=\"14.00\">σ &#45;]</text>\n</g>\n</g>\n</svg>\n"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_dfs = pl.scan_delta(source='./delta_lake1/product1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:06:34.063115Z",
     "start_time": "2024-03-06T17:06:33.744128Z"
    }
   },
   "id": "173e7b6cdf9ba18",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(sources_dfs.schema.get(\"effective_time\"), pl.Datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:10:30.132410Z",
     "start_time": "2024-03-06T17:10:30.127998Z"
    }
   },
   "id": "dcc9c9832926b2d0",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not isinstance(sources_dfs.schema.get(\"effective_time\"), pl.Datetime):\n",
    "    raise ValueError(\"wrong dtypes\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:09:26.381241Z",
     "start_time": "2024-03-06T17:09:26.378073Z"
    }
   },
   "id": "814a04289cd32631",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'num_source_rows': 7,\n 'num_target_rows_inserted': 0,\n 'num_target_rows_updated': 13,\n 'num_target_rows_deleted': 0,\n 'num_target_rows_copied': 1,\n 'num_output_rows': 14,\n 'num_target_files_added': 1,\n 'num_target_files_removed': 2,\n 'execution_time_ms': 109,\n 'scan_time_ms': 0,\n 'rewrite_time_ms': 8}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_scd_upsert_pl(\n",
    "    sources_dfs.lazy(),\n",
    "    updates_df,\n",
    "    \"product_code\",\n",
    "    './delta_lake1/product1',\n",
    "    ['color', 'size']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:43:12.363151Z",
     "start_time": "2024-03-06T16:43:12.235994Z"
    }
   },
   "id": "f46a5bef79afa551",
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
